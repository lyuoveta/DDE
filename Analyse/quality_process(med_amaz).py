# -*- coding: utf-8 -*-
"""quality process(med_amaz).ipynb"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_1m2URNigDUqhXpyQr3xbiIgVArvSAZ6
"""

import pandas as pd
import os
import re
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

data = pd.read_csv('markup_med.csv')
df = pd.read_csv('markup_amazon.csv')

data

df

data.drop(['age', 'duration, months', 'сondition'], axis=1, inplace=True)

data.rename(columns={ 'overall rating': 'ratings','dates_x':'dates','reviews_x':'reviews','Correct review ':'Correct review', 'Incorrect review ':'Incorrect review'}, inplace=True)

df.rename(columns={ 'review_dates': 'dates','review_ratings': 'ratings','Correct review':'Correct review'}, inplace=True)

combined_df = pd.concat([data, df], ignore_index=True, sort=False)

columns_to_convert = [
    'Blood and lymphatic system disorders',
    'Cardiac disorders',
    'Congenital familial and genetic disorders',
    'Ear and labyrinth disorders',
    'Endocrine disorders',
    'Eye disorders',
    'Gastrointestinal disorders',
    'General disorders and administration site conditions',
    'Hepatobiliary disorders',
    'Immune system disorders',
    'Infections and infestations',
    'Injury poisoning and procedural complications',
    'Investigations',
    'Metabolism and nutrition disorders',
    'Musculoskeletal and connective tissue disorders',
    'Neoplasms benign malignant and unspecified (incl cysts and polyps)',
    'Nervous system disorders',
    'Pregnancy puerperium and perinatal conditions',
    'Psychiatric disorders',
    'Renal and urinary disorders',
    'Reproductive system and breast disorders',
    'Respiratory thoracic and mediastinal disorders',
    'Skin and subcutaneous tissue disorders',
    'Social circumstances',
    'Surgical and medical procedures',
    'Vascular disorders',
    'Product issues',
    'Positive effects',
    'Correct review',
    'Incorrect review',
    'Incompatibility'
]

for column in columns_to_convert:
    combined_df[column] = combined_df[column].fillna(0).astype(int)

combined_df

combined_df.to_csv("combined_data(med_amaz).csv", index=False)

df = pd.read_csv('combined_data(med_amaz).csv')

df['dates'] = pd.to_datetime(df['dates'])

#data analysis
print('number of rows, columns', combined_df.shape)
df.info()

df.describe()

#missing values
df.isnull().sum()

#unique values
combined_df.nunique()

# dates column
df['dates'].describe()

df['dates'] = pd.to_datetime(df['dates'])
review_counts = df.groupby('dates')['reviews'].count().reset_index(name='review_count')

plt.figure(figsize=(10, 5))
plt.bar(review_counts['dates'], review_counts['review_count'], color='blue')

plt.xticks(rotation=45)
plt.xlabel('Дата')
plt.ylabel('Количество отзывов')
plt.title('Гистограмма отзывов по датам')

plt.tight_layout()
plt.show()

df['year'] = df['dates'].dt.year
reviews_per_year = df.groupby('year').size().reset_index(name='review_count')

plt.figure(figsize=(10, 6))
sns.barplot(x='year', y='review_count', data=reviews_per_year, color='skyblue')

plt.xlabel('Год')
plt.ylabel('Количество отзывов')
plt.title('Количество отзывов по годам')
plt.show()

df = df.drop('year', axis=1)

# name column

df['name'].value_counts()

review_counts = df.groupby('name')['reviews'].count().reset_index(name='review_count')
review_name = df.groupby('name').size().reset_index(name='review_count')

plt.figure(figsize=(10, 6))
sns.barplot(x='name', y='review_count', data=review_name, color='yellow')

plt.xticks(rotation=45)

plt.xlabel('Название')
plt.ylabel('Количество отзывов')
plt.title('Количество отзывов каждого названия')

plt.show()

# rating column
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.histplot(df['ratings'], kde=False, color='orange')
plt.title('Гистограмма рейтинга')
plt.xlabel('Рейтинг')

plt.subplot(1, 2, 2)
sns.boxplot(x=df['ratings'], color='lightblue')
plt.title('Boxplot рейтинга')
plt.xlabel('Рейтинг')

plt.tight_layout(pad=2)
plt.show()

df['ratings'].value_counts()

df['ratings'].describe()

#  анализа паттернов или трендов в данных обзорах во времени
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from scipy.stats import linregress

df.sort_values('dates', inplace=True)
reviews_count_by_date = df.resample('Y', on='dates').size()

average_rating_by_month = df.resample('Y', on='dates')['ratings'].mean()

fig, ax1 = plt.subplots(figsize=(15, 6))

color = 'tab:blue'
ax1.set_xlabel('Date')
ax1.set_ylabel('Number of Reviews', color=color)
ax1.bar(reviews_count_by_date.index, reviews_count_by_date.values, color=color, alpha=0.5, width=100, label='Number of Reviews')

ax1.tick_params(axis='y', labelcolor=color)
ax1.xaxis.set_major_locator(mdates.YearLocator())
ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))

ax1.set_ylim(0, 850)

ax2 = ax1.twinx()
color = 'tab:red'
ax2.set_ylabel('Average Rating', color=color)
ax2.plot(average_rating_by_month.index, average_rating_by_month.values, color=color, marker='o', label='Average Rating')
ax2.tick_params(axis='y', labelcolor=color)

x = mdates.date2num(average_rating_by_month.index)
y = average_rating_by_month.values

slope, intercept, r_value, p_value, std_err = linregress(x, y)

trend_y = intercept + slope * x

ax2.plot(average_rating_by_month.index, trend_y, color='green', label='Trend Line', linewidth=2)

lines, labels = ax1.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines2 + lines, labels2 + labels, loc='upper left')

fig.tight_layout()
plt.show()

biotin_df = df.loc[df['name'] == 'Biotin'].copy()

biotin_df.sort_values('dates', inplace=True)
reviews_count_by_date = biotin_df.resample('Y', on='dates').size()
average_rating_by_month = biotin_df.resample('Y', on='dates')['ratings'].mean()

fig, ax1 = plt.subplots(figsize=(15, 6))

color = 'tab:blue'
ax1.set_xlabel('Date')
ax1.set_ylabel('Number of Reviews', color=color)
ax1.bar(reviews_count_by_date.index, reviews_count_by_date.values, color=color, alpha=0.5, width=100, label='Number of Reviews')
ax1.tick_params(axis='y', labelcolor=color)
ax1.xaxis.set_major_locator(mdates.YearLocator())
ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))

ax2 = ax1.twinx()
color = 'tab:red'
ax2.set_ylabel('Average Rating', color=color)
ax2.plot(average_rating_by_month.index, average_rating_by_month.values, color=color, marker='o', label='Average Rating')
ax2.tick_params(axis='y', labelcolor=color)

x = mdates.date2num(average_rating_by_month.index)
y = average_rating_by_month.values
slope, intercept, r_value, p_value, std_err = linregress(x, y)
trend_y = intercept + slope * x

ax2.plot(average_rating_by_month.index, trend_y, color='green', label='Trend Line', linewidth=2)

lines, labels = ax1.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines2 + lines, labels2 + labels, loc='upper left')

fig.tight_layout()
plt.show()

biotin_df = df.loc[df['name'] == 'Colloidal_silver'].copy()

biotin_df.sort_values('dates', inplace=True)
reviews_count_by_date = biotin_df.resample('Y', on='dates').size()
average_rating_by_month = biotin_df.resample('Y', on='dates')['ratings'].mean()

fig, ax1 = plt.subplots(figsize=(15, 6))

color = 'tab:blue'
ax1.set_xlabel('Date')
ax1.set_ylabel('Number of Reviews', color=color)
ax1.bar(reviews_count_by_date.index, reviews_count_by_date.values, color=color, alpha=0.5, width=100, label='Number of Reviews')
ax1.tick_params(axis='y', labelcolor=color)
ax1.xaxis.set_major_locator(mdates.YearLocator())
ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))

ax2 = ax1.twinx()
color = 'tab:red'
ax2.set_ylabel('Average Rating', color=color)
ax2.plot(average_rating_by_month.index, average_rating_by_month.values, color=color, marker='o', label='Average Rating')
ax2.tick_params(axis='y', labelcolor=color)

x = mdates.date2num(average_rating_by_month.index)
y = average_rating_by_month.values
slope, intercept, r_value, p_value, std_err = linregress(x, y)
trend_y = intercept + slope * x

ax2.plot(average_rating_by_month.index, trend_y, color='green', label='Trend Line', linewidth=2)

lines, labels = ax1.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines2 + lines, labels2 + labels, loc='upper left')

fig.tight_layout()
plt.show()

# review column
import nltk
import seaborn as sns
import sklearn
import gensim
#import pyLDAvis
from wordcloud import WordCloud
from textblob import TextBlob
import spacy
#import textstat

df['reviews'].str.len().hist()
plt.title('Length of Reviews Distribution')

df1 = df.dropna(subset=['reviews'])
df1['reviews'].str.split().apply(lambda x: len(x)).hist()
plt.title('the number of words')

df1['reviews'].str.split().apply(lambda x: [len(i) for i in x]).map(lambda x: np.mean(x)).hist()
plt.title('average word length')

# data cleaning

from nltk.corpus import stopwords
nltk.download('stopwords')
stop=set(stopwords.words('english'))

corpus=[]

def plot_top_stopwords_barchart(text):
    stop=set(stopwords.words('english'))

    new= df['reviews'].str.split()
    new=new.values.tolist()
    corpus=[word for i in new for word in i]
    from collections import defaultdict
    dic=defaultdict(int)
    for word in corpus:
        if word in stop:
            dic[word]+=1

    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10]
    x,y=zip(*top)
    plt.bar(x,y)

plot_top_stopwords_barchart(df['reviews'])
plt.title('stopwords')

from collections import  Counter
def plot_top_non_stopwords_barchart(text):
    stop=set(stopwords.words('english'))

    new= df['reviews'].str.split()
    new=new.values.tolist()
    corpus=[word for i in new for word in i]

    counter=Counter(corpus)
    most=counter.most_common()
    x, y=[], []
    for word,count in most[:40]:
        if (word not in stop):
            x.append(word)
            y.append(count)

    sns.barplot(x=y,y=x)

plot_top_non_stopwords_barchart(df['reviews'])
plt.title('non stopwords')

from sklearn.feature_extraction.text import CountVectorizer

def plot_top_ngrams_barchart(text, n=2):
    stop=set(stopwords.words('english'))

    new = df['reviews'].str.split()
    new = new.values.tolist()
    corpus = [word for i in new for word in i]

    def _get_top_ngram(corpus, n=None):
        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)
        bag_of_words = vec.transform(corpus)
        sum_words = bag_of_words.sum(axis=0)
        words_freq = [(word, sum_words[0, idx])
                      for word, idx in vec.vocabulary_.items()]
        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)
        return words_freq[:10]

    top_n_bigrams=_get_top_ngram(text,n)[:10]
    x,y=map(list,zip(*top_n_bigrams))
    sns.barplot(x=y,y=x)

plot_top_ngrams_barchart(df['reviews'],2)
plt.title('top bigrams')

plot_top_ngrams_barchart(df['reviews'],3)
plt.title('top trigrams')

import string
import nltk
from nltk.corpus import stopwords
from nltk import PorterStemmer

STOPWORDS=stopwords.words("english")
def deEmojify(inputString):
    return inputString.encode('ascii', 'ignore').decode('ascii')
import string
import re

def clean_text(text):
    ps=PorterStemmer()

    text=deEmojify(text) # r
    text_cleaned="".join([x for x in text if x not in string.punctuation])

    text_cleaned=re.sub(' +', ' ', text_cleaned)
    text_cleaned=text_cleaned.lower()
    tokens=text_cleaned.split(" ")
    tokens=[token for token in tokens if token not in STOPWORDS]
    text_cleaned=" ".join([ps.stem(token) for token in tokens])


    return text_cleaned
df['cleaned_reviews']=df['reviews'].apply(lambda x:clean_text(x))
df.sample(5)

!pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
analyser = SentimentIntensityAnalyzer()

def sentiment_analyzer_scores(sentence):
    score = analyser.polarity_scores(sentence)
    return score

def compound_score(text):
    comp=sentiment_analyzer_scores(text)
    return comp['compound']
df['sentiment_score']=df['reviews'].apply(lambda x:compound_score(x))
df.sample(5)

def sentiment_category(score):
    if score >= 0.05:
        return "positive"
    elif score <= -0.05:
        return "negative"
    else:
        return "neutral"

df['review_category']=df['sentiment_score'].apply(lambda x:sentiment_category(x))
df.sample(5)

sns.countplot(df['review_category']).set_title("Distribution of Reviews Category")

positive_reviews=df.loc[df['review_category']=='positive','cleaned_reviews'].tolist()
positive_reviews[0:5]

negative_reviews=df.loc[df['review_category']=='negative','cleaned_reviews'].tolist()
negative_reviews[0:5]

from wordcloud import WordCloud
wordcloud = WordCloud(height=2000, width=2000, background_color='black')
wordcloud = wordcloud.generate(' '.join(df.loc[df['review_category']=='positive','cleaned_reviews'].tolist()))
plt.imshow(wordcloud)
plt.title("Most common words in positive customer comments")
plt.axis('off')
plt.show()

from wordcloud import WordCloud
wordcloud = WordCloud(height=2000, width=2000, background_color='black')
wordcloud = wordcloud.generate(' '.join(df.loc[df['review_category']=='negative','cleaned_reviews'].tolist()))
plt.imshow(wordcloud)
plt.title("Most common words in negative customer comments")
plt.axis('off')
plt.show()

df

names = df['name'].unique()

for name in names:
    positive_reviews = df.loc[(df['ratings'] > 3.5) & (df['name'] == name), 'cleaned_reviews'].tolist()
    negative_reviews = df.loc[(df['ratings'] <= 3.5) & (df['name'] == name), 'cleaned_reviews'].tolist()

    if positive_reviews:
        wordcloud = WordCloud(height=2000, width=2000, background_color='black').generate(' '.join(positive_reviews))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.title(f"Most common words in positive customer comments for group '{name}'")
        plt.axis('off')
        plt.show()

    if negative_reviews:
        wordcloud = WordCloud(height=2000, width=2000, background_color='black').generate(' '.join(negative_reviews))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.title(f"Most common words in negative customer comments for group '{name}'")
        plt.axis('off')
        plt.show()

df

df= df.dropna(subset=['cleaned_reviews'])

def map_rating_to_sentiment(rating):
    if rating > 3.5:
        return 'positive'
    elif rating < 3.5:
        return 'negative'
    else:
        return 'neutral'

df['real_sentiment'] = df['ratings'].apply(map_rating_to_sentiment)

df['correct_sentiment'] = df['real_sentiment'] == df['review_category']

correct_sentiment_counts = df['correct_sentiment'].value_counts()

correct_sentiment_counts

sentiment_comparison = df['correct_sentiment'].value_counts()

sentiment_comparison.plot(kind='bar', color=['green', 'red'])

plt.title('Сентимент: Сравнение Реального и Определенного Методом')
plt.xlabel('Совпадение сентимента')
plt.ylabel('Количество отзывов')
plt.xticks(ticks=[0, 1], labels=['Совпадает', 'Не совпадает'], rotation=0)
plt.show()

sentiment_match = df.groupby(['real_sentiment', 'correct_sentiment']).size().unstack(fill_value=0)

x_labels = sentiment_match.index

matches = sentiment_match[True]
mismatches = sentiment_match[False]

fig, ax = plt.subplots()

ax.plot(x_labels, matches, label='Совпадает', marker='o', linestyle='-')
ax.plot(x_labels, mismatches, label='Не совпадает', marker='x', linestyle='--')

plt.title('Сравнение сентимента по категориям')
plt.xlabel('Реальный Сентимент')
plt.ylabel('Количество отзывов')
plt.legend()
plt.grid(True)
plt.show()

df = df.drop(columns=['sentiment_score', 'review_category','real_sentiment','correct_sentiment'])

df['reviews'] = df['cleaned_reviews']

df = df.drop('cleaned_reviews', axis=1)

df

df.to_csv("data_med_amazon.csv", index=False)